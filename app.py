import streamlit as st
import pandas as pd
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
from openai import RateLimitError
import hashlib

# API í‚¤ ì„¤ì •
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ì²´í¬ë¦¬ìŠ¤íŠ¸ ì •ì˜
CHECKLIST = {
    "ì—­í• ": "í”„ë¡¬í”„íŠ¸ì— ì—­í• (ì˜ˆ: ë„ˆëŠ” ì„ ìƒë‹˜ì´ë‹¤)ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ê°€?",
    "ëŒ€ìƒ": "í”„ë¡¬í”„íŠ¸ì— ëŒ€ìƒ(ì˜ˆ: ì¤‘í•™ìƒì—ê²Œ ì„¤ëª…í•´ì¤˜)ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ê°€?",
    "ì •ë³´": "ë°°ê²½ ì •ë³´ ë˜ëŠ” ì„¤ëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
    "ì‘ì—…": "ëª…í™•í•œ ì‘ì—…(ì˜ˆ: ìš”ì•½í•´ì¤˜, í‘œë¡œ ì •ë¦¬í•´ì¤˜)ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ê°€?",
    "ê·œì¹™": "í•˜ì§€ ë§ì•„ì•¼ í•  ê¸ˆì§€ ì¡°ê±´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
    "ìŠ¤íƒ€ì¼": "ì–´ì¡°, í†¤, ìŠ¤íƒ€ì¼ ì§€ì‹œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
    "ì œì•½ì‚¬í•­": "ë¶„ëŸ‰, ì‹œê°„ ë“±ì˜ ì œì•½ ì¡°ê±´ì´ ëª…ì‹œë˜ì–´ ìˆëŠ”ê°€?",
    "í˜•ì‹/êµ¬ì¡°": "JSON, í‘œ, ëª©ë¡ ë“±ì˜ ì¶œë ¥ í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
    "ì˜ˆì‹œ": "ì˜ˆì‹œ ë˜ëŠ” ìƒ˜í”Œì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
    "í”„ë¡¬í”„íŠ¸ í…Œí¬ë‹‰": "few-shot, chain-of-thought ë“±ì˜ ê³ ê¸‰ ê¸°ë²•ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?",
}

# ê°„ë‹¨í•œ ìºì‹œ ì‹œìŠ¤í…œ
CACHE = {}

def prompt_hash(prompt):
    return hashlib.sha256(prompt.encode()).hexdigest()

# í‰ê°€ í•¨ìˆ˜ ì •ì˜
def evaluate_prompt(prompt):
    criteria_prompt = f"""
ë‹¤ìŒì€ í•™ìƒì´ ì‘ì„±í•œ AI í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤:
{prompt}

ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì•„ë˜ì˜ 10ê°€ì§€ í•­ëª©ì— ë”°ë¼ 0(ì•„ë‹ˆë‹¤)/1(ê·¸ë ‡ë‹¤)ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

{', '.join(CHECKLIST.keys())}

ë‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
{{
  "ì—­í• ": 0 ë˜ëŠ” 1,
  "ëŒ€ìƒ": 0 ë˜ëŠ” 1,
  ... ìƒëµ ...
}}
ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ì— í•™ìƒì—ê²Œ ì¤„ 1~2ë¬¸ì¥ í”¼ë“œë°±ì„ ì¨ì£¼ì„¸ìš”.
"""

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” êµì‚¬ì²˜ëŸ¼ í”„ë¡¬í”„íŠ¸ë¥¼ í‰ê°€í•˜ëŠ” ì—­í• ì„ ë§¡ì•˜ì–´."},
            {"role": "user", "content": criteria_prompt}
        ],
        temperature=0
    )

    return response.choices[0].message.content

# ì•ˆì „í•œ í‰ê°€ í•¨ìˆ˜ + ìºì‹œ + ì¬ì‹œë„ í¬í•¨
def safe_evaluate(prompt):
    h = prompt_hash(prompt)
    if h in CACHE:
        return CACHE[h]
    
    for wait in [10, 20, 30]:
        try:
            result = evaluate_prompt(prompt)
            CACHE[h] = result
            return result
        except RateLimitError:
            time.sleep(wait)
    return "â— í‰ê°€ ì‹¤íŒ¨ (RateLimit)"

# ë³‘ë ¬ ì²˜ë¦¬ í‰ê°€ í•¨ìˆ˜
def parallel_evaluate(prompts, max_threads=5):
    results = [None] * len(prompts)
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        future_to_index = {executor.submit(safe_evaluate, prompt): i for i, prompt in enumerate(prompts)}
        for future in as_completed(future_to_index):
            idx = future_to_index[future]
            try:
                results[idx] = future.result()
            except Exception as e:
                results[idx] = f"ì˜¤ë¥˜: {str(e)}"
    return results

# Streamlit UI ì‹œì‘
st.title("âš¡ ë¹ ë¥¸ í”„ë¡¬í”„íŠ¸ ìë™ ì±„ì ê¸° (GPT-3.5 ë³‘ë ¬)")

uploaded_file = st.file_uploader("ğŸ“„ í”„ë¡¬í”„íŠ¸ Excel ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])

if uploaded_file is not None:
    df = pd.read_excel(uploaded_file)
    if "í”„ë¡¬í”„íŠ¸" not in df.columns:
        st.error("âŒ 'í”„ë¡¬í”„íŠ¸' ì—´ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.success(f"{len(df)}ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        max_threads = st.slider("ğŸ”€ ë™ì‹œì— í‰ê°€í•  ìµœëŒ€ ì“°ë ˆë“œ ìˆ˜", 1, 10, 5)
        prompts = df["í”„ë¡¬í”„íŠ¸"].tolist()

        with st.spinner("â³ í”„ë¡¬í”„íŠ¸ í‰ê°€ ì¤‘..."):
            results = parallel_evaluate(prompts, max_threads=max_threads)

        df['í‰ê°€ê²°ê³¼'] = results
        st.dataframe(df)

        st.download_button("ğŸ“¥ í‰ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                           data=df.to_csv(index=False).encode('utf-8-sig'),
                           file_name="í”„ë¡¬í”„íŠ¸_í‰ê°€ê²°ê³¼.csv",
                           mime='text/csv')

